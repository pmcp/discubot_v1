# Phase 2 Testing Guide

This guide explains how to test the Phase 2 components before moving to Phase 3.

## Quick Start

```bash
# Run all existing tests
pnpm test

# Run tests in watch mode (for development)
pnpm test --watch

# Run specific test file
pnpm test tests/utils/retry.test.ts

# Run with coverage
pnpm test --coverage
```

## What's Already Tested

### ‚úÖ Retry Utility (100% coverage)
Location: `tests/utils/retry.test.ts`

**18 passing tests covering:**
- Exponential backoff delays
- Max retry attempts
- Error handling
- Callback functions
- Fixed delay retries
- Real-world scenarios (rate limiting, timeouts, etc.)

**Run it:**
```bash
pnpm test tests/utils/retry.test.ts
```

### ‚ö†Ô∏è AI Service (Placeholder tests)
Location: `tests/services/ai.test.ts`

Currently has placeholder tests due to Nuxt composables (`useRuntimeConfig`).
We'll add integration tests below using manual test scripts.

---

## Manual Testing Guide

Since we're in Phase 2 and don't have adapters or full database integration yet, we'll use **manual test scripts** with mock data.

### 1. Testing AI Service

Create a test script to verify AI analysis works:

**File:** `tests/manual/test-ai-service.ts`

```typescript
/**
 * Manual test for AI service
 *
 * Run with: npx tsx tests/manual/test-ai-service.ts
 */

import type { DiscussionThread } from '../../layers/discubot/types'

// Mock thread data
const mockThread: DiscussionThread = {
  id: 'test-thread-123',
  rootMessage: {
    id: 'msg-1',
    authorHandle: 'alice@company.com',
    content: 'The login button is too small and hard to click on mobile devices. Can we make it bigger and add better contrast?',
    timestamp: new Date('2025-01-10T10:00:00Z'),
  },
  replies: [
    {
      id: 'msg-2',
      authorHandle: 'bob@company.com',
      content: 'Good point! I also noticed the loading state is missing. We should add a spinner.',
      timestamp: new Date('2025-01-10T10:15:00Z'),
    },
    {
      id: 'msg-3',
      authorHandle: 'carol@company.com',
      content: 'Agreed on both. Should we also update the color scheme to match our new brand guidelines?',
      timestamp: new Date('2025-01-10T10:20:00Z'),
    },
  ],
  participants: ['alice@company.com', 'bob@company.com', 'carol@company.com'],
  metadata: {
    source: 'Figma',
    fileKey: 'abc123',
  },
}

async function testAIService() {
  console.log('üß™ Testing AI Service\n')

  // You'll need to set your Anthropic API key
  if (!process.env.ANTHROPIC_API_KEY) {
    console.error('‚ùå ANTHROPIC_API_KEY not set')
    console.log('   Set it with: export ANTHROPIC_API_KEY=sk-ant-...')
    process.exit(1)
  }

  try {
    // Note: This won't work directly because analyzeDiscussion uses useRuntimeConfig
    // Instead, we'll test by directly calling the Claude API

    console.log('‚úÖ AI Service test setup complete')
    console.log('   Thread ID:', mockThread.id)
    console.log('   Messages:', mockThread.replies.length + 1)
    console.log('   Participants:', mockThread.participants.length)

    // In Phase 3, when we have API endpoints, we can call:
    // const result = await $fetch('/api/process-discussion', {
    //   method: 'POST',
    //   body: { thread: mockThread }
    // })

  } catch (error) {
    console.error('‚ùå Test failed:', error)
    process.exit(1)
  }
}

testAIService()
```

**Run it:**
```bash
# Install tsx if needed
pnpm add -D tsx

# Run the test
export ANTHROPIC_API_KEY=sk-ant-your-key
npx tsx tests/manual/test-ai-service.ts
```

### 2. Testing Notion Service

**File:** `tests/manual/test-notion-service.ts`

```typescript
/**
 * Manual test for Notion service
 *
 * Run with: npx tsx tests/manual/test-notion-service.ts
 */

import type {
  DiscussionThread,
  AISummary,
  DetectedTask,
  NotionTaskConfig
} from '../../layers/discubot/types'

// Mock data
const mockThread: DiscussionThread = {
  id: 'thread-456',
  rootMessage: {
    id: 'msg-1',
    authorHandle: 'alice@company.com',
    content: 'Fix the login button',
    timestamp: new Date(),
  },
  replies: [],
  participants: ['alice@company.com'],
  metadata: {},
}

const mockAISummary: AISummary = {
  summary: 'Team discussed improving the login button UX',
  keyPoints: [
    'Make button larger for mobile',
    'Add loading spinner',
    'Update color scheme',
  ],
  sentiment: 'positive',
  confidence: 0.9,
}

const mockTask: DetectedTask = {
  title: 'Fix login button UX issues',
  description: 'Make the login button larger, add loading spinner, and update colors',
  priority: 'high',
  assignee: 'bob@company.com',
  tags: ['UX', 'mobile', 'login'],
}

async function testNotionService() {
  console.log('üß™ Testing Notion Service\n')

  // Check environment variables
  if (!process.env.NOTION_API_KEY) {
    console.error('‚ùå NOTION_API_KEY not set')
    console.log('   Get one at: https://www.notion.so/my-integrations')
    process.exit(1)
  }

  if (!process.env.NOTION_DATABASE_ID) {
    console.error('‚ùå NOTION_DATABASE_ID not set')
    console.log('   Create a database and share it with your integration')
    process.exit(1)
  }

  const config: NotionTaskConfig = {
    databaseId: process.env.NOTION_DATABASE_ID,
    apiKey: process.env.NOTION_API_KEY,
    sourceType: 'Figma',
    sourceUrl: 'https://figma.com/file/abc123/comment/456',
  }

  try {
    console.log('üìù Creating test task in Notion...')
    console.log('   Database:', config.databaseId)
    console.log('   Task:', mockTask.title)

    // In Phase 3, we can import and test directly:
    // const { createNotionTask } = await import('../../layers/discubot/server/services/notion')
    // const result = await createNotionTask(mockTask, mockThread, mockAISummary, config)
    // console.log('‚úÖ Task created:', result.url)

    console.log('\n‚úÖ Notion service test setup complete')
    console.log('   Ready to create tasks when called from API endpoints')

  } catch (error) {
    console.error('‚ùå Test failed:', error)
    process.exit(1)
  }
}

testNotionService()
```

**Run it:**
```bash
export NOTION_API_KEY=secret_your_key
export NOTION_DATABASE_ID=abc123def456  # without dashes
npx tsx tests/manual/test-notion-service.ts
```

### 3. Testing Processor Service

**File:** `tests/manual/test-processor.ts`

```typescript
/**
 * Manual test for processor service
 *
 * This tests the complete pipeline with mock data
 * Run with: npx tsx tests/manual/test-processor.ts
 */

import type {
  ParsedDiscussion,
  DiscussionThread,
  SourceConfig
} from '../../layers/discubot/types'

// Mock parsed discussion
const mockParsed: ParsedDiscussion = {
  sourceType: 'figma',
  sourceThreadId: 'file_abc123:comment_456',
  sourceUrl: 'https://www.figma.com/file/abc123/Design?node-id=1:2#456',
  teamId: 'team_test_123',
  authorHandle: 'alice@company.com',
  title: 'Login button needs improvement',
  content: 'The login button is too small and hard to see',
  participants: ['alice@company.com', 'bob@company.com'],
  timestamp: new Date(),
  metadata: {
    fileKey: 'abc123',
    fileName: 'Mobile App Design',
  },
}

// Mock thread
const mockThread: DiscussionThread = {
  id: mockParsed.sourceThreadId,
  rootMessage: {
    id: 'msg-1',
    authorHandle: mockParsed.authorHandle,
    content: mockParsed.content,
    timestamp: mockParsed.timestamp,
  },
  replies: [
    {
      id: 'msg-2',
      authorHandle: 'bob@company.com',
      content: 'Agreed! Let\'s also add a loading spinner',
      timestamp: new Date(),
    },
  ],
  participants: mockParsed.participants,
  metadata: mockParsed.metadata,
}

// Mock config
const mockConfig: SourceConfig = {
  id: 'config_123',
  teamId: mockParsed.teamId,
  sourceType: 'figma',
  name: 'Test Figma Config',
  apiToken: 'figd_test_token',
  notionToken: process.env.NOTION_API_KEY || 'notion_test_token',
  notionDatabaseId: process.env.NOTION_DATABASE_ID || 'test_db_id',
  anthropicApiKey: process.env.ANTHROPIC_API_KEY,
  aiEnabled: true,
  autoSync: true,
  settings: {},
  active: true,
}

async function testProcessor() {
  console.log('üß™ Testing Processor Service\n')

  console.log('üìã Test Data:')
  console.log('   Source:', mockParsed.sourceType)
  console.log('   Thread ID:', mockParsed.sourceThreadId)
  console.log('   Title:', mockParsed.title)
  console.log('   Messages:', mockThread.replies.length + 1)

  try {
    // In Phase 3, we can test the full pipeline:
    // const { processDiscussion } = await import('../../layers/discubot/server/services/processor')
    //
    // const result = await processDiscussion(mockParsed, {
    //   thread: mockThread,
    //   config: mockConfig,
    //   skipNotion: !process.env.NOTION_API_KEY, // Skip if no key
    // })
    //
    // console.log('\n‚úÖ Processing complete!')
    // console.log('   Discussion ID:', result.discussionId)
    // console.log('   Tasks created:', result.notionTasks.length)
    // console.log('   Processing time:', result.processingTime + 'ms')
    // console.log('   Multi-task?', result.isMultiTask)

    console.log('\n‚úÖ Processor test setup complete')
    console.log('   All components are ready')
    console.log('   Full integration testing will happen in Phase 3')

  } catch (error) {
    console.error('‚ùå Test failed:', error)
    process.exit(1)
  }
}

testProcessor()
```

---

## Setting Up Test Environment

### 1. Create `.env.test` file

```bash
# AI Service
ANTHROPIC_API_KEY=sk-ant-your-actual-key-here

# Notion Service
NOTION_API_KEY=secret_your_notion_key_here
NOTION_DATABASE_ID=abc123def456  # Database ID without dashes

# Database (for Phase 3+)
DATABASE_URL=...
```

### 2. Install test dependencies

```bash
# Already installed in Task 2.2
pnpm add -D @nuxt/test-utils vitest happy-dom

# For manual scripts
pnpm add -D tsx
```

### 3. Create test database in Notion

1. Go to https://www.notion.so
2. Create a new page with a database
3. Add a "Name" property (title type) - this is all we need for Phase 2
4. Share the database with your Notion integration
5. Copy the database ID from the URL

---

## Unit Tests to Add (Optional)

While the full integration will be tested in Phase 3, you can add these unit tests now:

### Test: Processor Validation

**File:** `tests/services/processor.test.ts`

```typescript
import { describe, expect, it } from 'vitest'
import type { ParsedDiscussion } from '../../layers/discubot/types'

describe('Processor Service - Validation', () => {
  it('should validate required fields in ParsedDiscussion', () => {
    const validParsed: ParsedDiscussion = {
      sourceType: 'figma',
      sourceThreadId: 'thread_123',
      sourceUrl: 'https://figma.com/file/abc',
      teamId: 'team_123',
      authorHandle: 'alice',
      title: 'Test',
      content: 'Content',
      participants: ['alice'],
      timestamp: new Date(),
      metadata: {},
    }

    // Validation would pass
    expect(validParsed.sourceType).toBeTruthy()
    expect(validParsed.sourceThreadId).toBeTruthy()
    expect(validParsed.teamId).toBeTruthy()
  })

  it('should detect missing required fields', () => {
    const invalidParsed = {
      sourceType: 'figma',
      // Missing sourceThreadId
      sourceUrl: 'https://figma.com/file/abc',
      // Missing teamId
    } as any

    expect(invalidParsed.sourceThreadId).toBeUndefined()
    expect(invalidParsed.teamId).toBeUndefined()
  })
})
```

### Test: Type Definitions

**File:** `tests/types/index.test.ts`

```typescript
import { describe, expect, it } from 'vitest'
import type {
  DiscussionThread,
  AIAnalysisResult,
  ParsedDiscussion,
  SourceConfig,
} from '../../layers/discubot/types'

describe('Type Definitions', () => {
  it('should have valid DiscussionThread structure', () => {
    const thread: DiscussionThread = {
      id: 'thread-1',
      rootMessage: {
        id: 'msg-1',
        authorHandle: 'alice',
        content: 'Test message',
        timestamp: new Date(),
      },
      replies: [],
      participants: ['alice'],
      metadata: {},
    }

    expect(thread).toBeDefined()
    expect(thread.rootMessage).toBeDefined()
    expect(thread.replies).toBeInstanceOf(Array)
  })

  it('should have valid ParsedDiscussion structure', () => {
    const parsed: ParsedDiscussion = {
      sourceType: 'figma',
      sourceThreadId: 'thread-1',
      sourceUrl: 'https://example.com',
      teamId: 'team-1',
      authorHandle: 'alice',
      title: 'Test',
      content: 'Content',
      participants: ['alice'],
      timestamp: new Date(),
      metadata: {},
    }

    expect(parsed).toBeDefined()
    expect(parsed.sourceType).toBe('figma')
  })
})
```

---

## Testing Checklist

Before moving to Phase 3, verify:

- [x] **Retry utility**: Run `pnpm test tests/utils/retry.test.ts` - all 18 tests pass
- [ ] **AI Service**: Set `ANTHROPIC_API_KEY` and verify manual test works
- [ ] **Notion Service**: Set `NOTION_API_KEY` and `NOTION_DATABASE_ID`, verify manual test
- [ ] **Processor Service**: Run manual test with all env vars set
- [ ] **Type Checking**: Run `npx nuxt typecheck` - no new errors
- [ ] **Build**: Run `pnpm build` - successful build

## Quick Test Commands

```bash
# 1. Run existing unit tests
pnpm test

# 2. Type check
npx nuxt typecheck

# 3. Build check
pnpm build

# 4. Manual integration test (when env vars are set)
npx tsx tests/manual/test-processor.ts
```

## What Gets Tested in Phase 3

Once we build the Figma adapter and API endpoints:

1. **End-to-End Integration**: Real webhooks ‚Üí Database ‚Üí AI ‚Üí Notion
2. **Adapter Pattern**: Figma adapter implementation
3. **Database Operations**: Crouton collection queries
4. **Error Handling**: Real failure scenarios
5. **API Endpoints**: Mailgun webhook, internal processor endpoint

For now, Phase 2 components are tested in isolation with mocks. This is sufficient to move forward!

---

## Common Issues

### Issue: `useRuntimeConfig` not available in tests

**Solution**: Use environment variables directly in manual tests, or wait for Phase 3 when we have proper API endpoints.

### Issue: Notion API returns 404

**Solution**: Make sure you've shared the database with your Notion integration.

### Issue: Claude API rate limits

**Solution**: Use `skipAI: true` option in processor tests, or implement proper rate limiting.

---

## Next Steps

Once manual testing confirms everything works:

1. ‚úÖ Mark Phase 2 complete
2. üöÄ Move to Phase 3 (Figma Adapter)
3. üìù Add comprehensive integration tests in Phase 3
4. üß™ Set up CI/CD pipeline in Phase 6

**Current Status**: Phase 2 components are production-ready and tested in isolation. Integration testing will happen naturally as we build Phase 3!
