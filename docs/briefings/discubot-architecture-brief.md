# Discubot: Architecture & Design Brief

**Project**: Discubot - Universal Discussion-to-Notion Sync System
**Date**: 2025-11-11
**Status**: Design Phase (Revised - Lean Architecture)
**Framework**: Nuxt 4 + Nuxt-Crouton + SuperSaaS
**Version**: 2.1 (rebuild from figno proof-of-concept)
**Architecture**: Lean MVP approach - 5 collections, 2 layers

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Design Goals](#design-goals)
3. [Learnings from Figno Proof-of-Concept](#learnings-from-figno)
4. [Core Architecture](#core-architecture)
5. [Source Adapter Pattern](#source-adapter-pattern)
6. [Layer Separation Strategy](#layer-separation-strategy)
7. [Data Flow](#data-flow)
8. [Security Architecture](#security-architecture)
9. [Team Management with SuperSaaS](#team-management)
10. [Key Architectural Decisions](#key-decisions)
11. [Technology Stack](#technology-stack)

---

## Executive Summary

Discubot is a universal discussion-to-task synchronization system that connects multiple collaboration platforms (Figma, Slack, Discord, etc.) with Notion task management. Built on Nuxt 4 and leveraging the Nuxt-Crouton CRUD framework, it uses a source adapter pattern to enable rapid addition of new discussion sources while maintaining a consistent AI-powered processing pipeline.

### Key Innovation: Source Adapter Pattern

Unlike the figno proof-of-concept which was tightly coupled to Figma, Discubot abstracts discussion sources behind a common interface. This allows:
- Adding new sources (Slack, Linear, GitHub) without touching core logic
- Reusing AI summarization and Notion integration across all sources
- Maintaining consistency in output format and user experience
- Rapid prototyping using Crouton-generated CRUD scaffolding

### System Flow

```
Discussion Source (Figma/Slack/etc.)
    â†“
Source Adapter (parses + validates)
    â†“
Unified Processing Pipeline (AI + Notion)
    â†“
Task Creation in Notion
    â†“
Confirmation back to Source
```

---

## Design Goals

### 1. **Generic & Extensible**
- Abstract "discussion source" pattern works for any service
- Adding a new source = implementing a simple adapter interface
- Core processing logic is source-agnostic

### 2. **Crouton-First Approach**
- Use `@friendlyinternet/nuxt-crouton` for all CRUD operations
- Auto-generate forms, tables, APIs, and database schemas
- Focus manual development on adapters and business logic

### 3. **SuperSaaS Multi-Tenancy**
- Team-based isolation via `nuxt-crouton-connector`
- Each team has separate configurations and data
- Automatic team scoping on all queries

### 4. **AI-Powered Intelligence**
- Claude AI for summarization and task detection
- Multi-task identification from single discussions
- Context-aware summary generation

### 5. **Production-Ready from Day One**
- Built on proven patterns from figno
- Robust error handling with retry logic
- Comprehensive logging and monitoring
- Progressive enhancement (add complexity as needed)

### 6. **Maintainable & Scalable**
- Clear separation of concerns (layers)
- Consistent patterns throughout codebase
- Easy to onboard new developers
- Horizontal scaling via Cloudflare Workers

---

## Learnings from Figno

### What Worked Well âœ…

#### 1. **Fire-and-Forget Webhook Pattern**
```typescript
// Webhook handler returns 200 OK immediately
export default defineEventHandler(async (event) => {
  // 1. Verify signature
  // 2. Create job in KV
  // 3. Trigger async processor
  return { ok: true } // < 3 seconds
})
```

**Why it works:**
- Prevents webhook timeouts
- Source platform doesn't retry
- Actual processing happens in background

#### 2. **Circuit Breaker for External APIs** â³ *Deferred to Phase 6*
```typescript
// From figno - proven effective but adds complexity
// For MVP: Use simple retry logic with exponential backoff
// Add circuit breaker when scale demands it
class CircuitBreaker {
  // Opens after 3 failures
  // Stays open for 30 seconds
  // Prevents cascade failures
}
```

**Why it worked in figno:**
- Protects against API outages
- Prevents queue backup
- Graceful degradation

**Why deferred for MVP:**
- Adds complexity before scale problems exist
- Simple retry logic sufficient for initial launch
- Can add when monitoring shows it's needed

#### 3. **AI Response Caching** ğŸ”§ *Simplified for MVP*
```typescript
// MVP: Simple Map-based cache (single-server deployment)
const summaryCache = new Map<string, { summary: string, timestamp: number }>()

async function getCachedSummary(thread: Thread) {
  const key = JSON.stringify(thread.messages)
  const cached = summaryCache.get(key)

  if (cached && Date.now() - cached.timestamp < 3600000) {
    return cached.summary
  }

  const summary = await claudeAPI.summarize(thread)
  summaryCache.set(key, { summary, timestamp: Date.now() })
  return summary
}

// Future: Upgrade to KV when deploying multi-region
```

**Why Map-based for MVP:**
- No external dependencies (KV)
- Works perfectly for single-server deployment
- Dramatically reduces API costs
- Faster response times
- Handles duplicate requests
- Can upgrade to KV in Phase 6 if multi-region deployment requires it

#### 4. **Multi-Task Detection**
```typescript
// AI can identify multiple tasks from one discussion
const result = await ai.detectTasks(thread)
// result.isMultiTask = true
// result.tasks = [
//   { title: "Fix login button", priority: "high" },
//   { title: "Update docs", priority: "low" }
// ]
```

**Why it works:**
- Single discussion â†’ multiple actionable tasks
- Reduces manual task creation
- Better captures discussion outcomes

#### 5. **Rate Limiting Notion API**
```typescript
// Sequential task creation with delays
for (const task of tasks) {
  await notion.createTask(task)
  await delay(200) // Prevent throttling
}
```

**Why it works:**
- Respects Notion's 3 req/sec limit
- Prevents 429 rate limit errors
- Ensures all tasks get created

### What Needs Improvement âŒ

#### 1. **Tight Coupling to Figma**
```typescript
// figno/server/services/figma.ts - Figma-specific
// figno/server/utils/emailParser.ts - Email-specific
// figno/server/database/schema.ts - 10 Figma-specific tables
```

**Problem:** Hard to add Slack without duplicating code

**Solution:** Abstract source interface, shared services

#### 2. **Configuration Sprawl**
```typescript
// 10+ database tables just for figno
fignoTeamConfigs
fignoAgents
fignoMonitoredFiles
fignoSyncJobs
fignoCommentThreads
fignoEmailConfigs
// ... and more
```

**Problem:** Complex relationships, hard to maintain

**Solution:** 4 generic collections with clear purpose
- discussions (with embedded thread data)
- configs (team-specific settings)
- jobs (processing tracking)
- tasks (audit trail + backup)

#### 3. **Limited Reusability**
```typescript
// AI service is good but Figma-centric in places
// Notion service works but not configurable
// Email parsing can't be reused for Slack
```

**Problem:** Can't easily port to other sources

**Solution:** Generic interfaces, dependency injection

---

## Core Architecture

### High-Level System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DISCUSSION SOURCES                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Figma   â”‚  â”‚  Slack   â”‚  â”‚  Linear  â”‚  â”‚  Future  â”‚   â”‚
â”‚  â”‚  Email   â”‚  â”‚  Webhook â”‚  â”‚  Webhook â”‚  â”‚  Sources â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SOURCE ADAPTERS (Plugin System)                 â”‚
â”‚  Each adapter implements:                                    â”‚
â”‚  - parseIncoming() â†’ ParsedDiscussion                       â”‚
â”‚  - fetchThread() â†’ DiscussionThread                         â”‚
â”‚  - postReply() â†’ boolean                                    â”‚
â”‚  - updateStatus() â†’ boolean                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            UNIFIED PROCESSING PIPELINE                       â”‚
â”‚  1. Discussion ingestion â†’ discussions collection            â”‚
â”‚  2. Thread building â†’ embedded in discussions.threadData     â”‚
â”‚  3. AI analysis (Claude) â†’ summary + tasks                  â”‚
â”‚  4. Task creation (Notion) â†’ tasks collection               â”‚
â”‚  5. Status update â†’ source adapter                          â”‚
â”‚  6. Job tracking â†’ jobs collection                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           CROUTON-GENERATED COLLECTIONS (5 Total)            â”‚
â”‚  - discussions: Raw discussion + embedded thread data        â”‚
â”‚  - configs: Team-specific source settings             â”‚
â”‚  - jobs: Job queue and status tracking                  â”‚
â”‚  - tasks: Created Notion tasks (audit trail + backup)       â”‚
â”‚  - userMappings: Source user â†’ Notion user mappings         â”‚
â”‚                                                              â”‚
â”‚  Removed for simplicity (MVP):                              â”‚
â”‚  - threads: Embedded as JSON in discussions.threadData      â”‚
â”‚  - sources: Hardcoded in adapter files (Figma, Slack)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 EXTERNAL INTEGRATIONS                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Notion     â”‚  â”‚  Claude AI   â”‚  â”‚  SuperSaaS   â”‚      â”‚
â”‚  â”‚   API        â”‚  â”‚  API         â”‚  â”‚  Teams       â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Responsibilities

#### Source Adapters (Manual)
- Parse incoming webhooks/emails
- Fetch complete thread data
- Post replies/confirmations
- Update status indicators (reactions)
- Validate source-specific configuration

#### Core Services (Manual - ported from figno)
- **AI Service**: Claude integration, caching, multi-task detection
- **Notion Service**: Task creation, rate limiting, field mapping
- **Processor Service**: Orchestrates the 7-stage pipeline

#### Collections (Generated by Crouton)
- **Forms**: Create/edit interfaces with validation
- **Tables**: List views with sorting, filtering, pagination
- **APIs**: RESTful endpoints for all CRUD operations
- **Composables**: Type-safe data fetching and mutations
- **Schemas**: Drizzle ORM database definitions

---

## Source Adapter Pattern

### The Problem

Each discussion platform has different:
- **Ingestion methods**: Email (Figma), Webhooks (Slack), Polling (Linear)
- **Data formats**: HTML emails, JSON payloads, GraphQL
- **Threading models**: Nested replies, flat threads, comment IDs
- **Authentication**: API tokens, OAuth, session cookies
- **Status updates**: Reactions (Figma), Emoji (Slack), Status fields (Linear)

### The Solution: Adapter Interface

All sources implement a standardized interface:

```typescript
// server/adapters/base.ts
export interface DiscussionSourceAdapter {
  // Unique identifier for this source type
  sourceType: 'figma' | 'slack' | 'linear' | 'github' | string

  // Parse incoming webhook/email into standardized format
  parseIncoming(payload: any): Promise<ParsedDiscussion>

  // Fetch full thread details from source
  fetchThread(
    threadId: string,
    config: SourceConfig
  ): Promise<DiscussionThread>

  // Post a reply back to the source
  postReply(
    threadId: string,
    message: string,
    config: SourceConfig
  ): Promise<boolean>

  // Update status indicators (reactions, emoji, status field)
  updateStatus(
    threadId: string,
    status: DiscussionStatus,
    config: SourceConfig
  ): Promise<boolean>

  // Validate source configuration
  validateConfig(config: SourceConfig): Promise<ValidationResult>

  // Health check
  testConnection(config: SourceConfig): Promise<boolean>
}
```

### Standardized Data Structures

All adapters output the same format:

```typescript
interface ParsedDiscussion {
  sourceType: string
  sourceThreadId: string      // Unique ID in source system
  sourceUrl: string           // Deep link to discussion
  teamId: string              // Resolved team
  authorHandle: string        // User who created
  title: string               // Subject/title
  content: string             // Main content
  participants: string[]      // All participants
  timestamp: Date
  metadata: Record<string, any>  // Source-specific data
}

interface DiscussionThread {
  id: string
  rootMessage: ThreadMessage
  replies: ThreadMessage[]
  participants: string[]
  metadata: Record<string, any>
}

interface ThreadMessage {
  id: string
  authorHandle: string
  content: string
  timestamp: Date
  attachments?: Attachment[]
}
```

### Adapter Implementations

#### Figma Adapter
```typescript
// server/adapters/figma.ts
export class FigmaAdapter implements DiscussionSourceAdapter {
  sourceType = 'figma'

  async parseIncoming(payload: MailgunPayload): Promise<ParsedDiscussion> {
    // Parse HTML email using cheerio
    // Extract file key from sender or links
    // Classify email type (comment vs invitation)
    // Return standardized ParsedDiscussion
  }

  async fetchThread(
    fileKey: string,
    commentId: string,
    config: SourceConfig
  ): Promise<DiscussionThread> {
    // Call Figma API: GET /v1/files/{fileKey}/comments
    // Find matching comment by text similarity (fuzzy match)
    // Build thread (root + replies)
    // Return DiscussionThread
  }

  async postReply(
    fileKey: string,
    commentId: string,
    message: string,
    config: SourceConfig
  ): Promise<boolean> {
    // POST /v1/files/{fileKey}/comments
    // parent_id: commentId
    // message: confirmation text with Notion link
  }

  async updateStatus(
    fileKey: string,
    commentId: string,
    status: DiscussionStatus,
    config: SourceConfig
  ): Promise<boolean> {
    // Map status to reactions:
    // processing â†’ ğŸ‘€ (eyes)
    // completed â†’ âœ… (white_check_mark)
    // failed â†’ âŒ (x)
    // POST /v1/files/{fileKey}/comments/{commentId}/reactions
  }
}
```

#### Slack Adapter
```typescript
// server/adapters/slack.ts
export class SlackAdapter implements DiscussionSourceAdapter {
  sourceType = 'slack'

  async parseIncoming(payload: SlackEventPayload): Promise<ParsedDiscussion> {
    // Verify Slack signature
    // Extract app_mention event
    // Parse channel, thread_ts, user, text
    // Return ParsedDiscussion
  }

  async fetchThread(
    channelId: string,
    threadTs: string,
    config: SourceConfig
  ): Promise<DiscussionThread> {
    // Call Slack API: conversations.replies
    // channel: channelId, ts: threadTs
    // Build thread from messages
    // Return DiscussionThread
  }

  async postReply(
    channelId: string,
    threadTs: string,
    message: string,
    config: SourceConfig
  ): Promise<boolean> {
    // POST chat.postMessage
    // channel: channelId, thread_ts: threadTs
    // text: confirmation with Notion link
  }

  async updateStatus(
    channelId: string,
    messageTs: string,
    status: DiscussionStatus,
    config: SourceConfig
  ): Promise<boolean> {
    // reactions.add
    // Map status to emoji (eyes, white_check_mark, x)
  }
}
```

### Adapter Benefits

1. **Isolation**: Each source is self-contained, changes don't affect others
2. **Testability**: Can mock adapters easily for testing
3. **Extensibility**: New sources = new adapter class, no core changes
4. **Consistency**: All sources produce same output format
5. **Flexibility**: Adapters can have source-specific optimizations

---

## User Mapping & Mention Resolution

### The Problem

When discussions from Slack or Figma mention users (e.g., `<@U123ABC456>` in Slack or `@user@example.com` in Figma), we need to properly @mention those users in the created Notion tasks. However, user IDs differ across platforms:
- **Slack**: User IDs like `U123ABC456`
- **Figma**: Email handles like `user@example.com`
- **Notion**: UUIDs like `b2e19928-b427-4aad-9a9d-fde65479b1d9`

### The Solution: User Mapping Collection

A dedicated `userMappings` collection maps external user identities to Notion users:

```typescript
interface UserMapping {
  sourceType: 'slack' | 'figma'
  sourceUserId: string           // U123ABC456 or user@example.com
  sourceTeamId: string            // T123ABC456 or file key
  notionUserId: string            // Notion UUID
  displayName: string             // Cached name
  email: string                   // For matching
  sourceProfile: json             // Full profile cache
  lastSyncedAt: Date
  active: boolean
}
```

### Mention Resolution Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: DETECT MENTIONS                                   â”‚
â”‚  Slack message: "Hey <@U123ABC456>, can you review this?"  â”‚
â”‚  Regex: /<@(U[A-Z0-9]+)>/g                                 â”‚
â”‚  Extracted: ["U123ABC456"]                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: RESOLVE TO NOTION USER                            â”‚
â”‚  Look up userMappings:                                      â”‚
â”‚    sourceType="slack"                                       â”‚
â”‚    sourceUserId="U123ABC456"                                â”‚
â”‚    sourceTeamId="T123ABC456"                                â”‚
â”‚  Result: notionUserId="b2e19928-..."                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: CREATE NOTION MENTION OBJECT                      â”‚
â”‚  {                                                          â”‚
â”‚    type: "mention",                                         â”‚
â”‚    mention: {                                               â”‚
â”‚      type: "user",                                          â”‚
â”‚      user: { id: "b2e19928-..." }                         â”‚
â”‚    },                                                       â”‚
â”‚    plain_text: "@John Doe"                                 â”‚
â”‚  }                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: INSERT INTO NOTION TASK                           â”‚
â”‚  Notion page rich_text:                                     â”‚
â”‚  [                                                          â”‚
â”‚    { type: "text", text: { content: "Hey " } },           â”‚
â”‚    { type: "mention", ... },  â† Proper @mention           â”‚
â”‚    { type: "text", text: { content: ", can you..." } }    â”‚
â”‚  ]                                                          â”‚
â”‚  Result: User gets notified in Notion! ğŸ””                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Slack OAuth Scope Enhancement

To fetch user information from Slack, we need the `users:read.email` scope:

```typescript
// server/api/oauth/slack/install.get.ts
const SLACK_SCOPES = [
  'channels:history',
  'chat:write',
  'reactions:write',
  'app_mentions:read',
  'im:history',
  'mpim:history',
  'users:read',        // Read basic user info
  'users:read.email'   // NEW: Required to fetch email for matching
]
```

### User Info Caching

The system caches user profile data to avoid repeated API calls:

```typescript
// server/services/userMapping.ts
export async function getOrCreateUserMapping(
  slackUserId: string,
  slackTeamId: string,
  config: SourceConfig
): Promise<UserMapping> {
  // 1. Check if mapping exists in database
  let mapping = await db.query.userMappings.findFirst({
    where: and(
      eq(userMappings.sourceType, 'slack'),
      eq(userMappings.sourceUserId, slackUserId),
      eq(userMappings.sourceTeamId, slackTeamId)
    )
  })

  // 2. If found and fresh (< 24 hours), return cached
  if (mapping && isRecent(mapping.lastSyncedAt, 24 * 60 * 60 * 1000)) {
    return mapping
  }

  // 3. Otherwise, fetch from Slack API
  const userInfo = await fetchSlackUserInfo(slackUserId, config.apiToken)

  // 4. Attempt to match Notion user by email
  const notionUserId = await matchNotionUserByEmail(
    userInfo.profile.email,
    config.notionToken
  )

  // 5. Create or update mapping
  if (!mapping && notionUserId) {
    mapping = await db.insert(userMappings).values({
      sourceType: 'slack',
      sourceUserId: slackUserId,
      sourceTeamId: slackTeamId,
      notionUserId,
      displayName: userInfo.real_name,
      email: userInfo.profile.email,
      sourceProfile: userInfo,
      lastSyncedAt: new Date(),
      active: true
    }).returning()
  } else if (mapping) {
    // Update existing
    await db.update(userMappings)
      .set({
        displayName: userInfo.real_name,
        email: userInfo.profile.email,
        sourceProfile: userInfo,
        lastSyncedAt: new Date()
      })
      .where(eq(userMappings.id, mapping.id))
  }

  return mapping
}
```

### Fallback Strategy

If no user mapping is found:
1. Show plain text username instead: `@username` (not a Notion mention)
2. Log warning for admin to create mapping
3. Task is still created successfully (graceful degradation)
4. No notification sent to Notion user

### Manual vs Automatic Mapping

**Automatic (Preferred):**
- Match by email address automatically
- Happens on first mention detection
- Requires `users:read.email` scope (Slack) or email in comments (Figma)

**Manual (Fallback):**
- Admin creates mappings in Admin UI
- Useful when emails don't match
- Supports multiple source workspaces â†’ same Notion user

### Admin UI for User Mappings

**List Page** (`/dashboard/[team]/discubot/user-mappings.vue`):
- Show all user mappings with filters
- Display: source type, source user, display name, Notion user, last synced
- Actions: Edit, Sync now, Delete

**Form** (Crouton-generated + enhanced):
- Select source type (Slack/Figma)
- Input source user ID or select from fetched list
- Select Notion user from dropdown (fetched via `users.list` API)
- Auto-sync profile data button
- Bulk import: Fetch all workspace users, attempt email matching

---

## Layer Separation Strategy

### Project Structure (Lean 2-Layer Approach)

```
discubot_v1/                           # Main project (SuperSaaS template)
â”œâ”€â”€ layers/
â”‚   â”œâ”€â”€ discussion/        # Crouton-generated (NEVER manually edit)
â”‚   â”‚   â”œâ”€â”€ collections/
â”‚   â”‚   â”‚   â”œâ”€â”€ discussions/           # Generated by Crouton
â”‚   â”‚   â”‚   â”œâ”€â”€ configs/               # Generated by Crouton
â”‚   â”‚   â”‚   â”œâ”€â”€ jobs/                  # Generated by Crouton
â”‚   â”‚   â”‚   â””â”€â”€ tasks/                 # Generated by Crouton
â”‚   â”‚   â””â”€â”€ nuxt.config.ts
â”‚   â”‚
â”‚   â””â”€â”€ discussion/                    # Manual code (business logic)
â”‚       â”œâ”€â”€ server/
â”‚       â”‚   â”œâ”€â”€ services/
â”‚       â”‚   â”‚   â”œâ”€â”€ ai.ts              # Claude AI (from figno) + Map cache
â”‚       â”‚   â”‚   â”œâ”€â”€ notion.ts          # Notion integration (from figno)
â”‚       â”‚   â”‚   â””â”€â”€ processor.ts       # 7-stage pipeline orchestration
â”‚       â”‚   â”œâ”€â”€ adapters/
â”‚       â”‚   â”‚   â”œâ”€â”€ base.ts            # Abstract adapter interface
â”‚       â”‚   â”‚   â”œâ”€â”€ figma.ts           # FigmaAdapter implementation
â”‚       â”‚   â”‚   â””â”€â”€ slack.ts           # SlackAdapter implementation
â”‚       â”‚   â”œâ”€â”€ api/
â”‚       â”‚   â”‚   â”œâ”€â”€ webhook/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ figma.post.ts  # Mailgun webhook
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ slack.post.ts  # Slack Events API
â”‚       â”‚   â”‚   â””â”€â”€ internal/
â”‚       â”‚   â”‚       â””â”€â”€ process.post.ts # Background processor
â”‚       â”‚   â””â”€â”€ utils/
â”‚       â”‚       â”œâ”€â”€ emailParser.ts     # Figma email parsing
â”‚       â”‚       â””â”€â”€ retry.ts           # Simple exponential backoff
â”‚       â”œâ”€â”€ types/
â”‚       â”‚   â””â”€â”€ index.ts               # Shared TypeScript types
â”‚       â”œâ”€â”€ components/                # Custom UI (extends Crouton)
â”‚       â””â”€â”€ nuxt.config.ts
â”‚
â”œâ”€â”€ crouton.config.mjs                 # Crouton generator config
â”œâ”€â”€ crouton/
â”‚   â”œâ”€â”€ schemas/                       # Collection schemas (4 total)
â”‚   â”‚   â”œâ”€â”€ discussion-schema.json     # With embedded threadData
â”‚   â”‚   â”œâ”€â”€ config-schema.json
â”‚   â”‚   â”œâ”€â”€ job-schema.json
â”‚   â”‚   â””â”€â”€ task-schema.json
â”‚   â””â”€â”€ crouton.config.mjs
â””â”€â”€ nuxt.config.ts
```

### Why This Separation?

#### **discussion/** (Generated - NEVER Manually Edit)
All CRUD operations for data management, auto-generated by Crouton.

**Responsibilities:**
- Database schemas (Drizzle ORM) for 4 collections
- REST APIs (GET/POST/PATCH/DELETE)
- Forms (Create/Edit with validation)
- Tables (List views with filtering)
- Composables (Type-safe data fetching)

**Why separate:**
- Fully regenerable by Crouton
- Can upgrade Crouton version easily
- Manual code doesn't pollute generated code
- Clear boundary: DON'T TOUCH THIS LAYER

**Collections:**
- discussions (with embedded threadData)
- configs (team-specific settings)
- jobs (7-stage pipeline tracking)
- tasks (audit trail + backup)

#### **discussion/** (Manual - All Business Logic)
All custom code, services, adapters, and UI.

**Responsibilities:**
- **Services**: AI (Claude), Notion, Processor (7-stage pipeline)
- **Adapters**: Base interface, Figma, Slack implementations
- **Webhooks**: Figma email, Slack events
- **Utilities**: Email parsing, retry logic
- **Types**: Shared TypeScript definitions
- **Components**: Custom UI extending Crouton

**Why consolidated:**
- Simpler navigation (one place for all manual code)
- Easier imports (no layer hopping)
- Both adapters in same location (easy comparison)
- Can still refactor to separate layers later if needed
- Follows KISS principle: start simple

**Source Types (Hardcoded):**
```typescript
// No database table needed - just constants
const SOURCE_TYPES = {
  FIGMA: {
    id: 'figma',
    name: 'Figma',
    adapterClass: FigmaAdapter,
    icon: 'ğŸ¨',
    requiresEmail: true
  },
  SLACK: {
    id: 'slack',
    name: 'Slack',
    adapterClass: SlackAdapter,
    icon: 'ğŸ’¬',
    requiresWebhook: true
  }
}
```

### Layer Dependencies

```
discussion/ â”€â”€â†’ discussion/
  â”œâ”€ services/
  â”œâ”€ adapters/
  â”œâ”€ api/
  â””â”€ components/
```

**Rules:**
1. `discussion/` depends on `discussion/` (for types, composables)
2. `discussion/` has no dependencies (pure Crouton)
3. All manual code lives in `discussion/`
4. All generated code lives in `discussion/`

### File Regeneration Strategy

**Generated (Never Manual Edit):**
- `layers/discubot/collections/**/*` - All Crouton output (~100 files)

**Manual (Safe to Edit):**
- `layers/discubot/**/*` - All business logic, services, adapters
- `crouton/schemas/*.json` - 4 collection definitions
- `crouton/crouton.config.mjs` - Generator configuration

**When to Regenerate:**
1. Schema changes â†’ Re-run `npx crouton-generate`
2. New collection (rare) â†’ Update crouton.config.mjs, regenerate
3. Crouton version upgrade â†’ Regenerate all collections

**File Counts:**
- Generated: ~100 files (4 collections Ã— ~25 files each)
- Manual: ~20-30 files (services, adapters, webhooks, utils)

---

## Data Flow

### Complete Processing Pipeline (7 Stages)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: INGESTION                                     â”‚
â”‚  Source: Figma/Slack/etc. â†’ Webhook â†’ Adapter          â”‚
â”‚  Output: discussions record (status: pending)           â”‚
â”‚  Duration: < 3 seconds (fire-and-forget)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: JOB CREATION                                  â”‚
â”‚  Create jobs record (status: pending)                   â”‚
â”‚  Store job ID in discussions.syncJobId                  â”‚
â”‚  Trigger background processor                           â”‚
â”‚  Duration: < 1 second                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: THREAD BUILDING                               â”‚
â”‚  Processor: Fetch full thread via adapter.fetchThread() â”‚
â”‚  Update jobs (stage: thread_building)               â”‚
â”‚  Create threads record with rootMessage + replies       â”‚
â”‚  Output: threads record (status: pending)               â”‚
â”‚  Duration: 2-5 seconds (depends on thread length)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: AI ANALYSIS                                   â”‚
â”‚  Update jobs (stage: ai_analysis)                   â”‚
â”‚  Call Claude AI:                                        â”‚
â”‚    1. generateSummary(thread) â†’ summary + key points   â”‚
â”‚    2. detectTasks(thread) â†’ isMultiTask + tasks[]      â”‚
â”‚  Update threads record: aiSummary, detectedTasks        â”‚
â”‚  Output: threads record (status: analyzed)              â”‚
â”‚  Duration: 3-8 seconds (depends on thread length)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 5: TASK CREATION                                 â”‚
â”‚  Update jobs (stage: task_creation)                     â”‚
â”‚  For each detected task:                                â”‚
â”‚    1. Create Notion page via Notion API                â”‚
â”‚    2. Create tasks record (notionPageId, url, etc.)    â”‚
â”‚    3. Add task ID to jobs.taskIds[]                    â”‚
â”‚    4. Wait 200ms (rate limiting)                       â”‚
â”‚  Output: tasks records (status: todo)                   â”‚
â”‚  Duration: 1-3 seconds per task                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 6: NOTIFICATION                                  â”‚
â”‚  Update jobs (stage: notification)                      â”‚
â”‚  Build confirmation message:                            â”‚
â”‚    Single: "âœ… Task created: {title}\nğŸ”— {notionUrl}" â”‚
â”‚    Multi:  "âœ… Created {N} tasks:\n1. ...\n2. ..."    â”‚
â”‚  Call adapter.postReply(threadId, message)              â”‚
â”‚  Call adapter.updateStatus(threadId, 'completed')       â”‚
â”‚  Update threads (status: notified)                      â”‚
â”‚  Duration: 1-2 seconds                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 7: COMPLETION                                    â”‚
â”‚  Update jobs:                                           â”‚
â”‚    - status: completed                                  â”‚
â”‚    - completedAt: now                                   â”‚
â”‚    - processingTime: duration                           â”‚
â”‚  Update discussions (status: completed, processedAt)    â”‚
â”‚  Total Duration: 10-20 seconds (end-to-end)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Error Handling Flow

```
ANY STAGE FAILS
â”‚
â”œâ”€ Update jobs:
â”‚    - status: failed or retrying
â”‚    - error: error message
â”‚    - errorStack: stack trace
â”‚    - attempts++
â”‚
â”œâ”€ Circuit Breaker Check:
â”‚    â””â”€ If open â†’ Fail fast, don't retry
â”‚
â”œâ”€ If attempts < maxAttempts (3):
â”‚    â”œâ”€ Calculate backoff: Math.pow(2, attempts) * 1000ms
â”‚    â”œâ”€ Wait exponentially (1s, 2s, 4s)
â”‚    â””â”€ Retry from current stage
â”‚
â””â”€ If attempts >= maxAttempts:
     â”œâ”€ Update jobs (status: failed)
     â”œâ”€ Update discussions (status: failed)
     â”œâ”€ Call adapter.updateStatus(threadId, 'failed')
     â”œâ”€ Optionally post error message to source
     â””â”€ Move to dead letter queue for manual review
```

### Real-World Example: Figma Comment

```
1. Designer mentions bot in Figma comment
   â””â”€ "@DiscubotAI please create a task for this"

2. Figma sends email to comments-team1@domain.com
   â””â”€ Mailgun receives, forwards to /api/webhook/figma

3. STAGE 1: Ingestion (2 seconds)
   â”œâ”€ Webhook verifies signature
   â”œâ”€ FigmaAdapter.parseIncoming(mailPayload)
   â”œâ”€ Creates discussion record:
   â”‚   - sourceType: 'figma'
   â”‚   - sourceThreadId: 'file_abc:comment_123'
   â”‚   - teamId: 'team1' (from email)
   â”‚   - title: 'Discussion about login button'
   â”‚   - status: 'pending'
   â””â”€ Returns 200 OK to Mailgun

4. STAGE 2: Job Creation (1 second)
   â”œâ”€ Creates syncJob record
   â”œâ”€ Links to discussion
   â””â”€ Triggers /api/internal/process-discussion

5. STAGE 3: Thread Building (3 seconds)
   â”œâ”€ FigmaAdapter.fetchThread(fileKey, commentId, config)
   â”œâ”€ Calls Figma API: GET /v1/files/{fileKey}/comments
   â”œâ”€ Finds comment by fuzzy text match
   â”œâ”€ Builds thread with root + 2 replies
   â””â”€ Creates threads record with 3 messages

6. STAGE 4: AI Analysis (5 seconds)
   â”œâ”€ AIService.generateSummary(thread)
   â”‚   â””â”€ "Discussion about making login button bigger and blue"
   â”œâ”€ AIService.detectTasks(thread)
   â”‚   â””â”€ Single task detected, isMultiTask: false
   â””â”€ Updates threads record with AI data

7. STAGE 5: Task Creation (2 seconds)
   â”œâ”€ NotionService.createTask({
   â”‚     title: "Make login button bigger and blue",
   â”‚     description: "Per designer feedback...",
   â”‚     sourceUrl: "https://figma.com/...",
   â”‚   })
   â”œâ”€ Creates tasks record:
   â”‚   - notionPageId: 'page_xyz'
   â”‚   - notionPageUrl: 'https://notion.so/...'
   â””â”€ Links to discussion and thread

8. STAGE 6: Notification (2 seconds)
   â”œâ”€ FigmaAdapter.postReply(fileKey, commentId,
   â”‚     "âœ… Task created: Make login button bigger\nğŸ”— https://notion.so/...")
   â””â”€ FigmaAdapter.updateStatus(fileKey, commentId, 'completed')
       â””â”€ Adds âœ… reaction to comment

9. STAGE 7: Completion (instant)
   â”œâ”€ jobs.status = 'completed'
   â”œâ”€ jobs.completedAt = now
   â”œâ”€ jobs.processingTime = 15000ms
   â””â”€ discussions.status = 'completed'

Total time: 15 seconds
```

---

## Security Architecture

### 1. Webhook Signature Verification

All webhooks must implement cryptographic signature verification:

#### Figma (Mailgun)
```typescript
// server/api/webhook/figma.post.ts
import crypto from 'crypto'

export default defineEventHandler(async (event) => {
  const signature = getHeader(event, 'x-mailgun-signature')
  const timestamp = getHeader(event, 'x-mailgun-timestamp')
  const token = getHeader(event, 'x-mailgun-token')

  const config = useRuntimeConfig()
  const signingKey = config.mailgunSigningKey

  // Verify HMAC-SHA256 signature
  const data = timestamp + token
  const expectedSignature = crypto
    .createHmac('sha256', signingKey)
    .update(data)
    .digest('hex')

  // Constant-time comparison (prevent timing attacks)
  if (!crypto.timingSafeEqual(
    Buffer.from(signature),
    Buffer.from(expectedSignature)
  )) {
    throw createError({ statusCode: 401, message: 'Invalid signature' })
  }

  // Timestamp check (prevent replay attacks)
  const age = Date.now() / 1000 - parseInt(timestamp)
  if (age > 300) { // 5 minutes
    throw createError({ statusCode: 401, message: 'Request too old' })
  }

  // Process webhook...
})
```

#### Slack
```typescript
// server/api/webhook/slack.post.ts
import crypto from 'crypto'

export default defineEventHandler(async (event) => {
  const signature = getHeader(event, 'x-slack-signature')
  const timestamp = getHeader(event, 'x-slack-request-timestamp')
  const rawBody = await readRawBody(event)

  const config = useRuntimeConfig()
  const signingSecret = config.slackSigningSecret

  // Check timestamp (prevent replay attacks)
  const currentTime = Math.floor(Date.now() / 1000)
  if (Math.abs(currentTime - parseInt(timestamp)) > 300) {
    throw createError({ statusCode: 401, message: 'Request too old' })
  }

  // Build signature base string
  const sigBaseString = `v0:${timestamp}:${rawBody}`

  // Calculate expected signature
  const expectedSignature = 'v0=' + crypto
    .createHmac('sha256', signingSecret)
    .update(sigBaseString, 'utf8')
    .digest('hex')

  // Constant-time comparison
  if (!crypto.timingSafeEqual(
    Buffer.from(signature),
    Buffer.from(expectedSignature)
  )) {
    throw createError({ statusCode: 401, message: 'Invalid signature' })
  }

  // Process webhook...
})
```

### 2. API Token Encryption â³ *Deferred to Phase 6*

**MVP Approach:** Store tokens in plain text in D1 database

**Why deferred:**
- D1 is already encrypted at rest (Cloudflare infrastructure)
- Environment variables (encryption key) have same access as database
- Adds complexity without significant security benefit for MVP
- Can add when pursuing SOC2/ISO27001 compliance

**Future implementation (Phase 6):**
```typescript
// server/utils/encryption.ts - FOR LATER
import crypto from 'crypto'

const config = useRuntimeConfig()
const ALGORITHM = 'aes-256-gcm'
const KEY = Buffer.from(config.encryptionKey, 'hex') // 32 bytes

export async function encryptToken(plainText: string): Promise<string> {
  const iv = crypto.randomBytes(16)
  const cipher = crypto.createCipheriv(ALGORITHM, KEY, iv)

  let encrypted = cipher.update(plainText, 'utf8', 'hex')
  encrypted += cipher.final('hex')

  const authTag = cipher.getAuthTag()

  return `${iv.toString('hex')}:${authTag.toString('hex')}:${encrypted}`
}

export async function decryptToken(encrypted: string): Promise<string> {
  const [ivHex, authTagHex, encryptedData] = encrypted.split(':')

  const iv = Buffer.from(ivHex, 'hex')
  const authTag = Buffer.from(authTagHex, 'hex')

  const decipher = crypto.createDecipheriv(ALGORITHM, KEY, iv)
  decipher.setAuthTag(authTag)

  let decrypted = decipher.update(encryptedData, 'hex', 'utf8')
  decrypted += decipher.final('utf8')

  return decrypted
}
```

**When to implement:**
- Pursuing SOC2 or ISO27001 certification
- Customer compliance requirements
- Handling highly sensitive data
- Database breach concerns

### 3. Rate Limiting

Prevent abuse with per-team and global rate limits:

```typescript
// nuxt.config.ts
export default defineNuxtConfig({
  nuxtHubRateLimit: {
    routes: {
      // Webhooks - generous limit
      '/api/webhook/*': {
        maxRequests: 100,
        intervalSeconds: 60
      },

      // Team APIs - per-team limit
      '/api/teams/:teamId/*': {
        maxRequests: 60,
        intervalSeconds: 60,
        keyGenerator: (event) => {
          const teamId = getRouterParam(event, 'teamId')
          return `team:${teamId}`
        }
      },

      // Admin APIs - strict limit
      '/api/admin/*': {
        maxRequests: 10,
        intervalSeconds: 60
      }
    }
  }
})
```

### 4. Input Validation

All user input must be validated with Zod:

```typescript
// server/api/teams/[id]/source-configs.post.ts
import { z } from 'zod'

const sourceConfigSchema = z.object({
  sourceId: z.string().min(1),
  name: z.string().min(1).max(200),
  apiToken: z.string().min(1),
  notionToken: z.string().min(1),
  notionDatabaseId: z.string().regex(/^[a-f0-9]{32}$/),
  anthropicApiKey: z.string().optional(),
  aiEnabled: z.boolean().default(true),
  autoSync: z.boolean().default(true)
})

export default defineEventHandler(async (event) => {
  const body = await readBody(event)

  // Validate input
  const validation = sourceConfigSchema.safeParse(body)
  if (!validation.success) {
    throw createError({
      statusCode: 400,
      message: 'Invalid input',
      data: validation.error.errors
    })
  }

  const data = validation.data
  // Process validated data...
})
```

### 5. Team-Based Authorization

All operations must verify team membership:

```typescript
// server/utils/auth.ts
export async function requireTeamMember(teamId: string, userId: string) {
  const membership = await db.query.teamMembers.findFirst({
    where: and(
      eq(teamMembers.teamId, teamId),
      eq(teamMembers.userId, userId),
      eq(teamMembers.status, 'active')
    )
  })

  if (!membership) {
    throw createError({
      statusCode: 403,
      message: 'You are not a member of this team'
    })
  }

  return membership
}

export async function requireTeamAdmin(teamId: string, userId: string) {
  const membership = await requireTeamMember(teamId, userId)

  if (!['owner', 'admin'].includes(membership.role)) {
    throw createError({
      statusCode: 403,
      message: 'You do not have admin permissions for this team'
    })
  }

  return membership
}
```

#### Usage
```typescript
// server/api/teams/[id]/source-configs.post.ts
export default defineEventHandler(async (event) => {
  const teamId = getRouterParam(event, 'id')
  const { user } = await requireUserSession(event)

  // Only admins can create source configs
  await requireTeamAdmin(teamId, user.id)

  // Process request...
})
```

### 6. Environment Variables

Sensitive configuration via runtime config:

```typescript
// nuxt.config.ts
export default defineNuxtConfig({
  runtimeConfig: {
    // Private (server-only)
    encryptionKey: process.env.ENCRYPTION_KEY, // 32-byte hex
    mailgunSigningKey: process.env.MAILGUN_SIGNING_KEY,
    slackSigningSecret: process.env.SLACK_SIGNING_SECRET,
    anthropicApiKey: process.env.ANTHROPIC_API_KEY, // Global fallback
    notionApiKey: process.env.NOTION_API_KEY, // Global fallback

    public: {
      // Public (client-side safe)
      appUrl: process.env.NUXT_PUBLIC_APP_URL
    }
  }
})
```

```bash
# .env (never commit!)
ENCRYPTION_KEY=64-character-hex-string-here
MAILGUN_SIGNING_KEY=your-mailgun-key
SLACK_SIGNING_SECRET=your-slack-secret
ANTHROPIC_API_KEY=sk-ant-api03-...
NOTION_API_KEY=secret_...
```

### Security Checklist

**MVP (Phases 1-5):**
- [x] Webhook signature verification (HMAC-SHA256)
- [x] Timestamp validation (prevent replay attacks)
- [x] Constant-time comparison (prevent timing attacks)
- [x] Rate limiting (per-team + global)
- [x] Input validation (Zod schemas)
- [x] Team-based authorization
- [x] Environment variable isolation
- [x] SQL injection protection (Drizzle ORM)
- [x] XSS prevention (Nuxt UI components)

**Phase 6 (Deferred):**
- [ ] API token encryption (AES-256-GCM) - Deferred until compliance requires it
- [ ] Circuit breaker pattern - Deferred until scale requires it
- [ ] Advanced monitoring/alerting - Basic logging sufficient for MVP

---

## Team Management with SuperSaaS

### SuperSaaS Integration

Discubot leverages the `nuxt-crouton-connector` SuperSaaS integration for team-based multi-tenancy:

```javascript
// crouton.config.mjs
connectors: {
  users: {
    type: 'supersaas',
    autoInstall: true,
    copyFiles: true,
    updateAppConfig: true
  }
}

flags: {
  useTeamUtility: true  // CRITICAL: Enables team-based features
}
```

### What SuperSaaS Provides

#### 1. Automatic Team Scoping

All Crouton-generated collections automatically include:
```typescript
// Auto-added fields (don't manually define!)
{
  id: string          // nanoid()
  teamId: string      // Current user's team
  userId: string      // Current user's ID
  createdAt: Date     // Auto timestamp
  updatedAt: Date     // Auto timestamp
}
```

#### 2. Team-Scoped APIs

All generated endpoints automatically filter by team:

```typescript
// GET /api/teams/:teamId/discussions
// Only returns discussions for this team

// POST /api/teams/:teamId/discussions
// Auto-sets teamId from URL param

// PATCH /api/teams/:teamId/discussions/:id
// Verifies discussion belongs to team before updating
```

#### 3. Team Member References

Collections can reference SuperSaaS users:

```json
{
  "assignedTo": {
    "type": "string",
    "refTarget": ":users",
    "meta": {
      "label": "Assigned To",
      "description": "SuperSaaS team member"
    }
  }
}
```

This generates a `ReferenceSelect` component that shows team members.

### Team Resolution Strategy

For webhook-based sources (where no user is logged in), we need to resolve the team:

#### Figma (Email-Based)
```typescript
// server/adapters/figma.ts
async parseIncoming(payload: MailgunPayload): Promise<ParsedDiscussion> {
  // Extract team slug from email address
  // comments-team1@domain.com â†’ team1
  const recipient = payload.recipient
  const match = recipient.match(/comments-([^@]+)@/)
  const teamSlug = match?.[1]

  if (!teamSlug) {
    throw new Error('Could not resolve team from email')
  }

  // Look up team by slug
  const team = await db.query.teams.findFirst({
    where: eq(teams.slug, teamSlug)
  })

  if (!team) {
    throw new Error(`Team not found: ${teamSlug}`)
  }

  return {
    teamId: team.id,
    // ... other fields
  }
}
```

#### Slack (Workspace-Based)
```typescript
// server/adapters/slack.ts
async parseIncoming(payload: SlackEventPayload): Promise<ParsedDiscussion> {
  // Slack provides team_id in payload
  const slackWorkspaceId = payload.team_id

  // Look up source config by Slack workspace ID
  const config = await db.query.configs.findFirst({
    where: and(
      eq(configs.slackWorkspaceId, slackWorkspaceId),
      eq(configs.active, true)
    )
  })

  if (!config) {
    throw new Error(`No config found for Slack workspace: ${slackWorkspaceId}`)
  }

  return {
    teamId: config.teamId,
    // ... other fields
  }
}
```

### Team Switching

When users switch teams in the SuperSaaS UI:
1. Active team changes in session
2. All Crouton composables automatically re-fetch data
3. Cache is invalidated for old team
4. New team's data is fetched and cached

This happens automatically with no manual code required.

---

## Key Architectural Decisions

### Decision 1: Crouton for CRUD, Manual for Adapters

**Decision:** Use Crouton to generate all collection management code, implement adapters and services manually.

**Rationale:**
- Crouton excels at CRUD boilerplate (forms, tables, APIs)
- Adapter logic is business-specific and unique per source
- Clear boundary: generated = data layer, manual = business logic
- Can upgrade Crouton without affecting adapters

**Alternative Considered:** All manual code
**Why Rejected:** 150+ files of repetitive CRUD code, high maintenance burden

---

### Decision 2: Adapter Pattern Over Monolithic Service

**Decision:** Each source implements a standardized adapter interface.

**Rationale:**
- Isolates source-specific complexity
- Easy to add new sources without touching existing code
- Can disable sources independently (feature flags)
- Testable in isolation with mocks
- Follows Open/Closed Principle (open for extension, closed for modification)

**Alternative Considered:** Single service with switch statements
**Why Rejected:** Becomes unmaintainable as sources grow, violates SRP

---

### Decision 3: Separate Layers for Core, Adapters, Collections

**Decision:** Three-layer architecture: core services, source adapters, Crouton collections.

**Rationale:**
- Core services (AI, Notion) are shared across all sources
- Adapters are isolated and independently deployable
- Collections are regenerable and don't mix with custom code
- Clear dependency graph prevents circular dependencies

**Alternative Considered:** Single layer with everything
**Why Rejected:** Tight coupling, hard to test, regeneration destroys custom code

---

### Decision 4: Fire-and-Forget Webhooks

**Decision:** Webhooks return 200 OK immediately, process in background.

**Rationale:**
- Source platforms timeout after 3-10 seconds
- Processing takes 10-20 seconds (AI + Notion)
- Prevents duplicate webhook deliveries
- Better user experience (no waiting)

**Alternative Considered:** Synchronous processing
**Why Rejected:** Timeouts cause retries, duplicate tasks, poor UX

---

### Decision 5: KV Storage for Job Queue

**Decision:** Use Cloudflare KV (via NuxtHub) for job queue with TTL.

**Rationale:**
- Built into NuxtHub (no extra dependencies)
- TTL-based automatic cleanup (24 hours)
- Fast reads/writes on edge
- Simple API (no message queue complexity)

**Alternative Considered:** Bull/BullMQ with Redis
**Why Rejected:** Extra infrastructure, overkill for use case, not edge-compatible

---

### Decision 6: Encrypt Tokens at Rest

**Decision:** Encrypt all API tokens before database storage using AES-256-GCM.

**Rationale:**
- Compliance requirement (SOC 2, GDPR)
- Protects against database leaks
- Minimal performance overhead
- Standard practice for SaaS

**Alternative Considered:** Store plain text
**Why Rejected:** Security vulnerability, compliance failure

---

### Decision 7: Circuit Breaker for External APIs

**Decision:** Implement circuit breaker pattern for AI, Notion, and source APIs.

**Rationale:**
- Prevents cascade failures during outages
- Fast-fails during known issues
- Automatic recovery when service returns
- Proven pattern from figno (worked well)

**Alternative Considered:** Simple retry logic
**Why Rejected:** Can make outages worse by hammering failing service

---

### Decision 8: AI Response Caching

**Decision:** Cache AI responses for 1 hour using MD5 hash of input.

**Rationale:**
- Dramatically reduces API costs (Claude is expensive)
- Faster responses for duplicate discussions
- Handles webhook retries gracefully
- 1 hour TTL balances freshness vs. cost

**Alternative Considered:** No caching
**Why Rejected:** Cost prohibitive, slower responses

---

### Decision 9: Rate Limit Notion API

**Decision:** Sequential task creation with 200ms delays.

**Rationale:**
- Notion API limit: 3 requests/second
- Prevents 429 rate limit errors
- Ensures all tasks get created
- Simple implementation (no queue needed)

**Alternative Considered:** Parallel creation
**Why Rejected:** Causes rate limit errors, lost tasks

---

### Decision 10: SuperSaaS for Multi-Tenancy

**Decision:** Use SuperSaaS template + nuxt-crouton-connector for team management.

**Rationale:**
- Battle-tested team management (auth, permissions, billing)
- Automatic team scoping in Crouton
- No need to build user management from scratch
- Follows your existing pattern

**Alternative Considered:** Custom team management
**Why Rejected:** Reinventing the wheel, high maintenance burden

---

## Technology Stack

### Core Framework
- **Nuxt 4**: Modern Vue framework with SSR, SSG, and edge deployment
- **Vue 3**: Composition API for reactive UI components
- **TypeScript**: Type safety across entire codebase

### CRUD Generation
- **@friendlyinternet/nuxt-crouton**: Auto-generates collections, forms, tables, APIs
- **@friendlyinternet/nuxt-crouton-connector**: SuperSaaS team integration

### Database & ORM
- **D1 (Cloudflare)**: SQLite database via NuxtHub
- **Drizzle ORM**: Type-safe database queries and migrations
- **Zod**: Runtime validation and type inference

### External APIs
- **Claude AI (Anthropic)**: Summarization and task detection
- **Notion API**: Task creation and management
- **Figma API**: Comment threading and reactions
- **Slack API**: Thread fetching and message posting

### Infrastructure (NuxtHub)
- **Cloudflare Workers**: Edge serverless functions
- **Cloudflare KV**: Key-value storage for job queue and caching
- **Cloudflare D1**: Distributed SQLite database
- **Cloudflare R2**: Blob storage for attachments (future)

### Authentication
- **SuperSaaS**: Team-based auth and user management
- **Nuxt Auth Utils**: Session management

### UI Components
- **Nuxt UI 4**: Component library (NOT v2/v3!)
- **Tailwind CSS**: Utility-first styling
- **Headless UI**: Accessible components

### Development Tools
- **pnpm**: Fast package manager
- **ESLint**: Code linting
- **Prettier**: Code formatting
- **Vitest**: Unit testing
- **Playwright**: E2E testing

### Package Dependencies

```json
{
  "dependencies": {
    "@friendlyinternet/nuxt-crouton": "^1.2.0",
    "@friendlyinternet/nuxt-crouton-connector": "^0.1.0",
    "@anthropic-ai/sdk": "^0.27.0",
    "@notionhq/client": "^2.2.15",
    "nuxt": "^3.13.0",
    "drizzle-orm": "^0.33.0",
    "zod": "^3.23.0",
    "nanoid": "^5.0.0",
    "cheerio": "^1.0.0"
  },
  "devDependencies": {
    "@nuxthub/core": "^0.7.0",
    "vitest": "^2.0.0",
    "playwright": "^1.47.0"
  }
}
```

### Environment Requirements

```bash
# Required
Node.js >= 20
pnpm >= 9

# Optional (for local development)
Docker (for local D1 emulation)
```

---

## Summary

Discubot v2 represents a complete architectural evolution from the figno proof-of-concept, built with a **lean, pragmatic approach**:

**From:** Figma-specific monolith with 10+ tables and tight coupling
**To:** Generic adapter-based system with **5 collections** and clear separation

**From:** Manual CRUD code for every entity
**To:** Crouton-generated collections with auto-generated forms, tables, APIs

**From:** Single-source limitation
**To:** Multi-source support via standardized adapter interface

**From:** Complex 4-layer structure with premature abstractions
**To:** Simple 2-layer structure: generated + manual code

**From:** Over-engineered for imagined scale
**To:** Right-sized for MVP, extensible when needed

### What We're Building (MVP)

The result is a lean system that:
- âœ… Supports multiple discussion sources (Figma, Slack, easily add more)
- âœ… Leverages Crouton for rapid development (~100 generated files)
- âœ… Maintains essential security (signatures, rate limiting, validation)
- âœ… Scales horizontally on Cloudflare edge
- âœ… Easy to extend with new sources (implement one adapter)
- âœ… Production-ready error handling (retry logic, 7-stage pipeline)
- âœ… Team-based multi-tenancy via SuperSaaS

### What We're Deferring (Phase 6)

Advanced features to add when scale/compliance demands:
- â³ Circuit breaker pattern (when API outages become a problem)
- â³ Token encryption (when pursuing SOC2/ISO27001)
- â³ KV-based caching (when deploying multi-region)

### Philosophy

This architecture follows the KISS principle from CLAUDE.md:
> "Start simple, add complexity only when proven necessary"

We're building for **current needs** (2 sources, 0 users) not **imagined future scale** (10+ sources, 1000+ users). We can always add complexity later when real problems emerge.

**Next steps:**
- See `discubot-crouton-schemas.md` for exact collection definitions
- See `discubot-implementation-roadmap.md` for phased implementation plan
- See `discubot-architecture-decisions.md` for detailed rationale

---

**Document Version**: 2.1 (Revised - Lean Architecture + User Mappings)
**Last Updated**: 2025-11-12
**Author**: Architecture Planning for Discubot v2
**Changes**: Added userMappings collection for Notion @mentions, documented mention resolution workflow
**Next Review**: After Phase 5 completion
